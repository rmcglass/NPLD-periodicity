{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tunes depth profiles of Korolev to each other using dynamic time warping algorithm\n",
    "## Depth profiles should be .csv files located in ./data/korolev2 and ./data/NPLD\n",
    "## Plots tunings and computes cross-correlation\n",
    "## Tests XC value against XC's from tunings to random profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import pandas as pd\n",
    "import glob\n",
    "from radarfuncs import *\n",
    "from DTWfuncs import *\n",
    "from lmfit.models import SkewedGaussianModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import csv files -- Korolev\n",
    "csv_importk = glob.glob(\"data/korolev2/*zoom.csv\")\n",
    "csv_importk = sorted(csv_importk, key=lambda x: x[-9])\n",
    "\n",
    "column_names = ['depth', 'value']\n",
    "x_listk = []\n",
    "y_listk = []\n",
    "fit_listk = []\n",
    "\n",
    "#load data and put into lists\n",
    "for i in csv_importk:\n",
    "    csv = pd.read_csv(i, names=column_names, skiprows=2) #skips headers\n",
    "    \n",
    "    x = csv.depth.to_list()\n",
    "    y = csv.value.to_list()\n",
    "    \n",
    "    peak = y.index(max(y[0:50])) #finds surface return\n",
    "    \n",
    "    x = x[peak+5:]\n",
    "    y = y[peak+5:]\n",
    "    \n",
    "    #convert pixels to meters\n",
    "    #x = p2m_waterice(x)\n",
    "    \n",
    "    x_listk.append(x)\n",
    "    y_listk.append(y)\n",
    "    \n",
    "    ##compute line to fit synthetic data to\n",
    "    # Skewed Gaussian fit\n",
    "    model = SkewedGaussianModel()\n",
    "    params = model.make_params(amplitude=(max(y)), center=min(x)+20, sigma=20, gamma=1.5)\n",
    "    result = model.fit(y, params, x=x)\n",
    "    fit = result.best_fit +np.mean(y[-150:]) # prevents fit from damping out all of the noise on right-handed side\n",
    "    \n",
    "    fit_listk.append(fit)\n",
    "    \n",
    "print(csv_importk)\n",
    "\n",
    "#Import csv files -- NPLD\n",
    "csv_importn = glob.glob(\"data/NPLD/*zoom.csv\")\n",
    "csv_importn = sorted(csv_importn, key=lambda x: int(x[-10]+x[-9]))\n",
    "csv_importn = csv_importn[3:4]+csv_importn[7:8]\n",
    "\n",
    "column_names = ['depth', 'value']\n",
    "x_listn = []\n",
    "y_listn = []\n",
    "fit_listn = []\n",
    "\n",
    "#load data and put into lists\n",
    "for i in csv_importn:\n",
    "    csv = pd.read_csv(i, names=column_names, skiprows=2) #skips headers\n",
    "    \n",
    "    x = csv.depth.to_list()\n",
    "    y = csv.value.to_list()\n",
    "    \n",
    "    peak = y.index(max(y[0:50])) #finds surface return\n",
    "    \n",
    "    x = x[peak+5:]\n",
    "    y = y[peak+5:]\n",
    "    \n",
    "    #convert pixels to meters\n",
    "    #x = p2m_waterice(x)\n",
    "    \n",
    "    x_listn.append(x)\n",
    "    y_listn.append(y)\n",
    "    \n",
    "    ##compute line to fit synthetic data to\n",
    "    # Skewed Gaussian fit\n",
    "    model = SkewedGaussianModel()\n",
    "    params = model.make_params(amplitude=(max(y)), center=min(x)+20, sigma=20, gamma=1.5)\n",
    "    result = model.fit(y, params, x=x)\n",
    "    fit = result.best_fit +np.mean(y[-150:]) # prevents fit from damping out all of the noise on right-handed side\n",
    "    \n",
    "    fit_listn.append(fit)\n",
    "    \n",
    "print(csv_importn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Use DTW to tune each profile to the other profiles\n",
    "#plot results, produce XC\n",
    "\n",
    "\n",
    "for i in range(len(csv_importk)):\n",
    "    prof1 = csv_importk[i]\n",
    "    d1 = x_listk[i]\n",
    "    v1 = y_listk[i]\n",
    "    fit = fit_listk[i]\n",
    "    \n",
    "    for j in range(len(csv_importn)):\n",
    "        prof2 = csv_importn[j]\n",
    "        d2 = x_listn[j]\n",
    "        v2 = y_listn[j]\n",
    "        fitn = fit_listn[j]\n",
    "            \n",
    "        xtune, XC, tstd, dt, W, D, tx = dtw_mars(v1,v2)\n",
    "        #print(W)\n",
    "        #np.savetxt('cost_'+str(i)+str(j)+'.csv', D, delimiter=',')\n",
    "        \n",
    "        #Run MonteCarlo simulation to assess quality of tunings\n",
    "        #A strong match is when real XC is nigher than 90% of all XCs from tunings to random profiles\n",
    "\n",
    "        XC_rs = [] #holds cross correlation values for 1000 random profiles\n",
    "        syn = []\n",
    "        #W_rs = []\n",
    "        \n",
    "        for a in range(1000):\n",
    "            r=ar1(d2,v2,fitn) #this creates a random synthetic record with similar properties\n",
    "            syn.append(r)\n",
    "            xtune_r, XC_r, tstd_r, dt_r, W_r, D_r, tx_r = dtw_mars(v1,r)\n",
    "            XC_rs.append(XC_r)\n",
    "            #W_rs.append(W_r)\n",
    "            \n",
    "        #check if correlation is good\n",
    "        XC_mean = np.mean(XC_rs)\n",
    "        XC_95 = XC_mean + 2*np.std(XC_rs)\n",
    "        GoodFit = False\n",
    "        if XC >= XC_95:\n",
    "            GoodFit = True\n",
    "        \n",
    "        # Set up the axes with gridspec\n",
    "        plt.rcParams.update({'font.size': 16})\n",
    "        fig = plt.figure(figsize=(13,7))\n",
    "        grid = plt.GridSpec(6, 10, hspace=0.4, wspace=0.7)\n",
    "        main = fig.add_subplot(grid[:-2, 1:5])\n",
    "        y_prof = fig.add_subplot(grid[:-2, 0], xticklabels=[], sharey=main)\n",
    "        x_prof = fig.add_subplot(grid[-2, 1:5], yticklabels=[], sharex=main)\n",
    "        hist = fig.add_subplot(grid[:-2,6:])\n",
    "        x_tune = fig.add_subplot(grid[-1, 1:5], yticklabels=[], sharex=main)\n",
    "        \n",
    "\n",
    "        # DTW min path on main\n",
    "        main.pcolor(D)\n",
    "        main.plot([0,len(v1)-1], [0,len(xtune)-1],'w--', linewidth=2)\n",
    "        main.plot(W[:,1], W[:,0],'r-', linewidth=3)\n",
    "        main.xaxis.tick_top()\n",
    "        main.yaxis.tick_right()\n",
    "\n",
    "        # x profile -- what gets tuned\n",
    "        xax= np.subtract(d2,d2[0])\n",
    "        x_prof.plot(xax, v2)\n",
    "        #x_prof.set_xlabel(prof2)\n",
    "        #x_prof.set_ylabel(\"Radar power\")\n",
    "\n",
    "        #y profile -- fixed\n",
    "        yax = np.subtract(d1,d1[0])\n",
    "        y_prof.plot(np.multiply(-1,v1),yax)\n",
    "        y_prof.set_ylabel(prof1 + \"\\nDepth (px)\")\n",
    "        y_prof.set_xlabel(\"Radar power\", fontsize = 14)\n",
    "        \n",
    "        #X profile -- tuned\n",
    "        xax= np.subtract(tx,tx[0])\n",
    "        x_tune.plot(xax, xtune)\n",
    "        x_tune.set_xlabel(prof2 + \"\\ntop: original, bottom: tuned \\nDepth (px)\")\n",
    "        x_tune.set_ylabel(\"Radar power\", fontsize = 14)\n",
    "    \n",
    "        # histogram of XC values\n",
    "        hist.hist(XC_rs) #bins = n_bins\n",
    "        hist.set_title(\"Cross-correlation values: n=\"+str(len(XC_rs)))\n",
    "        if GoodFit == False:\n",
    "            hist.axvline(x = XC, color = 'r', ls='--')\n",
    "        else:\n",
    "            hist.axvline(x = XC, color = 'g', ls = '--')\n",
    "        \n",
    "        fig.savefig(\"K\"+str(i+1)+\"N\"+str(j+1)+\".png\")\n",
    "        \n",
    "        print(\"XC of \"+prof1+\" and \"+prof2+\": \"+str(XC))\n",
    "        print(\"Avg XC of \"+prof1+ \" and 1000 random profiles:\"+str(XC_mean)+ \". 95% threshold:\"+str(XC_95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the axes with gridspec\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# fig = plt.figure(figsize=(13,7))\n",
    "# grid = plt.GridSpec(6, 10, hspace=0.8, wspace=1.4)\n",
    "# main = fig.add_subplot(grid[:-2, 1:5])\n",
    "# y_prof = fig.add_subplot(grid[:-2, 0], xticklabels=[], sharey=main)\n",
    "# x_prof = fig.add_subplot(grid[-2, 1:5], yticklabels=[], sharex=main)\n",
    "# hist = fig.add_subplot(grid[:-2,6:])\n",
    "# x_tune = fig.add_subplot(grid[-1, 1:5], yticklabels=[], sharex=main)\n",
    "# #x_prof.set_xlabel(\"korolev1234567_1zoom\")\n",
    "# x_tune.set_xlabel(\"korolev1234567_1zoom \\ntop: original, bottom: tuned \\nDepth (px)\")\n",
    "# y_prof.set_xlabel(\"Radar power\", fontsize = 14)\n",
    "# x_tune.set_ylabel(\"Radar power\", fontsize = 14)\n",
    "\n",
    "# hist.set_title(\"Cross-correlation values:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
